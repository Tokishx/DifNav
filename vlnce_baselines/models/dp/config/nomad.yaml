project_name: vln_nomad
run_name: vln_nomad



# training setup
use_wandb: True # set to false if you don't want to log to wandb
train: True
batch_size: 256
epochs: 100
gpu_ids: [0]
num_workers: 4
lr: 1e-4
optimizer: adamw
clipping: False
max_norm: 1.
scheduler: "cosine"
warmup: True 
warmup_epochs: 4
cyclic_period: 10
plateau_patience: 3
plateau_factor: 0.5
seed: 0

pretrained_path: "data/checkpoints/{scene}.pth"

# model params
model_type: vln_nomad
vision_encoder: vln_visual_encoder
# encoding_size: 256
encoding_size: 768
obs_encoder: efficientnet-b0
attn_unet: False
cond_predict_scale: False
mha_num_attention_heads: 4
mha_num_attention_layers: 4
mha_ff_dim_factor: 4
# down_dims: [64, 128, 256]
down_dims: [192, 384, 768]

# diffusion_transformer
input_dim: 2
output_dim: 2
horizon: 1
n_obs_steps: 1
cond_dim: 768
causal_attn: True

# n_cond_layers: 0 

# n_layer: 8
# n_head: 4

n_layer: 12
n_head: 12

n_emb: 768
p_drop_emb: 0.0
p_drop_attn: 0.01

# diffusion model params
num_diffusion_iters: 10
# num_diffusion_iters: 100

# mask 
goal_mask_prob: 0.5

# normalization for the action space
normalize: True

# context
context_type: temporal
context_size: 3 # 5
alpha: 1e-4

# distance bounds for distance and action and distance predictions 
distance:
  min_dist_cat: 0
  max_dist_cat: 20
action:
  min_dist_cat: 3
  max_dist_cat: 20

# action output params
len_traj_pred: 1
# len_traj_pred: 4
learn_angle: False
action_execution_horizon: 1
# action_execution_horizon: 2
action_dim: 2

# dataset specific parameters
image_size: [96, 96] # width, height
datasets:
  R2R-CE:
  # generation
    metric_waypoint_spacing: 0.25
    waypoint_spacing: 2
  # go_stanford:
  #   data_folder: /home/<username>/nomad_dataset/go_stanford_cropped # datasets/stanford_go_new
  #   train: /home/<username>/data_splits/go_stanford/train/
  #   test: /home/<username>/data_splits/go_stanford/test/
  #   end_slack: 0
  #   goals_per_obs: 2 # increase dataset size
  #   negative_mining: True
  # cory_hall:
  #   data_folder: /home/<username>/nomad_dataset/cory_hall/
  #   train: /home/<username>/data_splits/cory_hall/train/
  #   test: /home/<username>/data_splits/cory_hall/test/
  #   end_slack: 3 # because many trajectories end in collisions
  #   goals_per_obs: 1
  #   negative_mining: True
  # tartan_drive:
  #   data_folder: /home/<username>/nomad_dataset/tartan_drive/
  #   train: /home/<username>/data_splits/tartan_drive/train/
  #   test: /home/<username>/data_splits/tartan_drive/test/
  #   end_slack: 3 # because many trajectories end in collisions
  #   goals_per_obs: 1
  #   negative_mining: True
  # sacson:
  #   data_folder: /home/<username>/nomad_dataset/sacson/
  #   train: /home/<username>/data_splits/sacson/train/
  #   test: /home/<username>/data_splits/sacson/test/
  #   end_slack: 3 # because many trajectories end in collisions
  #   goals_per_obs: 1
  #   negative_mining: True
  # private datasets (uncomment if you have access)
  # seattle:
  #   data_folder: /home/<username>/nomad_dataset/seattle/
  #   train: /home/<username>/data_splits/seattle/train/
  #   test: /home/<username>/data_splits/seattle/test/
  #   end_slack: 0
  #   goals_per_obs: 1
  #   negative_mining: True
  # scand:
  #   data_folder: /home/<username>/nomad_dataset/scand/
  #   train: /home/<username>/data_splits/scand/train/
  #   test: /home/<username>/data_splits/scand/test/
  #   end_slack: 0
  #   goals_per_obs: 1
  #   negative_mining: True

# logging stuff
## =0 turns off
print_log_freq: 100 # in iterations
image_log_freq: 1000 #0 # in iterations
num_images_log: 8 #0 
pairwise_test_freq: 0 # in epochs
eval_fraction: 0.25
wandb_log_freq: 10 # in iterations
eval_freq: 1 # in epochs